import numpy as np
from io import StringIO
import os
from ..process_data import process
from collections import OrderedDict
import networkx as nx
from networkx.algorithms import isomorphism
import time
import datetime
from ..data import char_to_res_name,res_name_to_char
import re
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.Align.Applications import MuscleCommandline
from Bio.SeqRecord import SeqRecord
from Bio.SeqUtils import seq1
from Bio.SVDSuperimposer import SVDSuperimposer
from Bio import AlignIO
from Bio.PDB.StructureAlignment import StructureAlignment
from pandas import DataFrame
from numpy import linalg as LA


def strip_res_number(u):
    for i in range(0, len(u)):
        if u[i].isdigit():
            return u[:i]

def strip_res_num_and_chain(u):
    for i in range(0, len(u)):
        if u[i]=="_":
            u = u[:i]
            break
    start_idx = -1
    end_idx = -1
    for i in range(0, len(u)):
        if start_idx==-1 and u[i].isdigit():
            start_idx=i
        if end_idx==-1 and u[i]==")":
            end_idx = i
    return u[:start_idx] + u[end_idx+1:]

def node_match(node1, node2):
    return node1['num_label'] == node2['num_label']


def edge_match(edge1, edge2):
    return edge1['num_label'] == edge2['num_label']


class FrequentSubgraph():
    '''
    Stores all information regarding a frequent subgraph identified by the gSpan algorithm.

    Attributes
    ----------
    id: str
        Unique identifier for frequent subgraph. 
    generic_subgraph: :class:`networkx.Graph`
        Graph representation of frequent subgraph found by gSpan algorithm
    support: list of str
        List of PDB IDs which contain this subgraph
    specific_subgraphs: dict of pdb id (str): list of :class:`networkx.Graph`
        Dict which contains specific instances of this frequent subgraph in each PDB. Contained in each list are 
        :class:`networkx.Graph` derived from the graphs generated by the :class:`~pyemap.emap` class which match 
        the pattern of this frequent subgraph.
    support_number: int
        Number of PDBs this frequent subgraph was identified in 
    '''

    def __init__(self, G, graph_number, support):
        '''Initializes FrequentSubgraph object.

        Parameters
        ----------
        G: :class:`networkx.Graph`
            Graph representation of frequent subgraph found by gSpan algorithm
        graph_number: int
            Unique numerical ID of frequent subgraph
        support: list of str
            List of PDB IDs which contain this subgraph
        '''
        self.generic_subgraph = G
        self.support = support
        self.specific_subgraphs = {}
        self.support_number = len(support)
        self.id = str(graph_number) + "_" + str(self._gen_node_rep()) + "_" + str(self.support_number)

    def general_report(self):
        ''' Generates general report which describes this frequent subgraph.
        '''
        full_str = ""
        full_str+= "ID:" + str(self.id) + "\n"
        full_str+= "Support:" + str(self.support_number) + "\n"
        full_str+= "Where:" + str(self.support) + "\n"
        full_str+= "Adjacency list:\n"
        G = self.generic_subgraph
        for node in G.nodes:
            full_str+= G.nodes[node]['label'] + str(node) + ":["
            for neighbor in G.neighbors(node):
                full_str+= G.nodes[neighbor]['label'] + str(neighbor) + "(" + str(G.edges[(node,neighbor)]['num_label']) + "), "
            full_str=full_str[:-2]
            full_str+="]\n"
        return full_str

    def full_report(self,emaps):
        ''' Generates full report for all PDBs supported by this frequent subgraph.
        '''
        full_str = ""
        for pdb_id in self.support:
            full_str+=self._report_for_pdb(pdb_id,emaps)+"\n\n"
        return full_str

    def _report_for_graph(self,G):
        full_str = ""
        full_str+= str(G.graph["pdb_id"]) + "\n"
        if hasattr(G.graph,'eigval'):
            full_str+= "Eigenvalue:" + str(G.graph['eigval']) + "\n"
        full_str+="Nodes\n"
        for node in G.nodes:
            full_str+=G.nodes[node]['label']
            full_str+= " Position in alignment:" + str(G.nodes[node]['aligned_resnum'])
            full_str+="\n"
        full_str+="Adjacency list:\n"
        for node in G.nodes:
            full_str+= G.nodes[node]['label'] + ":["
            for neighbor in G.neighbors(node):
                dist = '{0:.2f}'.format(G.edges[(node,neighbor)]['distance'])
                full_str+= G.nodes[neighbor]['label'] + "(" + str(dist) + "), "
            full_str=full_str[:-2]
            full_str+="]\n"
        return full_str

    def _report_for_pdb(self,pdb_id,emaps):
        full_str = ""
        emap = emaps[pdb_id]
        sgs = self.specific_subgraphs[pdb_id]
        full_str+= "PDB:" + pdb_id + "\n"
        full_str+= "Occurences:" + str(len(sgs)) + "\n"
        for i,G in enumerate(sgs):
            full_str+="Nodes\n"
            for node in G.nodes:
                full_str+=G.nodes[node]['label']
                res = emap.residues[node]
                if 'aligned_resnum' in G.nodes[node]:
                    full_str+= " Position in alignment:" + str(res.aligned_residue_number)
                full_str+="\n"
            full_str+="Subgraph " + str(i+1) + " adjacency list:\n"
            for node in G.nodes:
                full_str+= G.nodes[node]['label'] + ":["
                for neighbor in G.neighbors(node):
                    dist = '{0:.2f}'.format(G.edges[(node,neighbor)]['distance'])
                    full_str+= G.nodes[neighbor]['label'] + "(" + str(dist) + "), "
                full_str=full_str[:-2]
                full_str+="]\n"
        return full_str

    def _gen_node_rep(self):
        node_rep = ""
        for node, node_data in self.generic_subgraph.nodes(data=True):
            node_rep = ''.join([node_rep, node_data['label']])
        return node_rep

    def visualize_subgraph_in_ngl(self, emap, idx):
        ''' Gets visualization of subgraph in ngl viewer

        Parameters
        ----------
            emap: :class:`~pyemap.emap`
                :class:`~pyemap.emap` object containing the specific subgraph
            idx: int
                Index of specific subgraph to be visualized
        '''
        colors = {"F": "orange", "Y": "blue", "W": "red", "H": "green"}
        label_texts = []
        labeled_atoms = []
        color_list = []
        selection_strs = []
        G = self.specific_subgraphs[emap.pdb_id][idx]
        for res in G.nodes:
            label_texts.append(res)
            try:
                if res not in emap.eta_moieties:
                    color_list.append(colors[res[0]])
                    labeled_atoms.append(".CA")
                else:
                    color_list.append("pink")
                    labeled_atoms.append(next(emap.residues[res].get_atoms()).name)
            except KeyError:
                color_list.append("pink")
                labeled_atoms.append(next(emap.residues[res].get_atoms()).name)
            selection_strs.append(emap.residues[res].ngl_string)
        return label_texts, labeled_atoms, color_list, selection_strs
    
    def clustering(self):
        all_graphs = []
        for pdb_id in self.support:
            all_graphs += self.specific_subgraphs[pdb_id]
        dims = (len(all_graphs),len(all_graphs))
        D = np.zeros(dims)
        A = np.zeros(dims)
        for i in range(0,len(all_graphs)):
            for j in range(i+1,len(all_graphs)):
                G1 = all_graphs[i]
                G2 = all_graphs[j]
                distance = 0
                mismatches = 0
                for k,node1 in enumerate(G1.nodes):
                    if strip_res_number(node1) in char_to_res_name:
                        node2 = list(G2.nodes())[k]
                        distance+= np.absolute(G1.nodes[node1]['aligned_resnum'] - G2.nodes[node2]['aligned_resnum'])
                if distance<10:
                    A[i][j] = 1/(distance+1)
                    A[j][i] = 1/(distance+1)
                else:
                    A[i][j] = 0.01
                    A[j][i] = 0.01   
            D[i][i] = np.sum(A[i])
        L = D - A
        eigv,eigvc=LA.eig(L)
        eigv = np.real(eigv)
        eigvc = np.real(eigvc)
        idx = eigv.argsort()
        eigv = eigv[idx]
        eigvc = eigvc[:,idx] 
        eigvc2 = eigvc[:,1]
        eigenvector_sorted = {}
        for i,val in enumerate(eigvc2):
            all_graphs[i].graph['eigval'] = val
            rounded_val = np.round(val,decimals=4)
            if rounded_val not in eigenvector_sorted:
                eigenvector_sorted[rounded_val] = [all_graphs[i]]
            else:
                graphs = eigenvector_sorted[rounded_val]
                graphs.append(all_graphs[i])
                eigenvector_sorted[rounded_val] =  graphs
        tuples = []
        for key,val in eigenvector_sorted.items():
            tuples.append((key,val))
        tuples.sort(key=lambda x: len(x[1]), reverse=True)
        eigenvector_sorted = {}
        for key,val in tuples:
            eigenvector_sorted[key] = val
        self.eigenvector_sorted = eigenvector_sorted

                            
                        



class PDBGroup():
    '''
    Contains all information regarding the group of proteins being analyzed, and all of the of
    the frequent subgraphs identified by the gSpan algorithm.

    Attributes
    ----------
    title: str
        Title of PDB group 
    emaps: dict of str: :class:`~pyemap.emap`
        Dict of PDBs being analyzed by PyeMap. The keys are PDB IDs, meaning that only one :class:`~pyemap.emap` object per PDB ID is allowed.
    temp_dir: str
        Path where temporary files are to be stored   
    frequent_subgraphs: dict of str: :class:`~pyemap.common_paths.FrequentSubgraph`
        Dict of frequent subgraphs found by GSpan. Keys are the unique IDs of the :class:`~pyemap.common_paths.FrequentSubgraph` objects.

    '''
    def __init__(self, title, temp_dir=""):
        ''' Initializes PDBGroup object
        
        Parameters
        ----------
        title: str
            Title of PDB group 
        temp_dir: str
            Path where temporary files are to be stored 
        '''
        self.title = title
        self.emaps = OrderedDict()
        self.temp_dir = temp_dir
        self.frequent_subgraphs = {}
        self.res_to_num_label = {}
        self.num_label_to_res = {}
        self.edge_thresholds = []
        self.parameters = {}
        self.included_eta_moieties = {}
        self.included_chains = {}
        self.included_standard_residues = []
        self.sequences = {}
        self.aligned_sequences = {}

    def _clean_subgraphs(self):
        self.frequent_subgraphs = {}
        self.res_to_num_label = {}
        self.num_label_to_res = {}
        self.edge_thresholds = []

    def _reset_process(self):
        self.parameters = {}
        self.included_eta_moieties = {}
        self.included_chains = {}
        self.included_standard_residues = []
        self.sequences = {}
        self.aligned_sequences = {}
        self._clean_subgraphs()

    def _align_structures(self):
        ref_atoms = []
        ref_pdb = None
        for pdb_id,emap in self.emaps.items():
            cur_atoms = list(emap.structure[0].get_atoms())
            if len(cur_atoms) > len(ref_atoms):
                ref_atoms = cur_atoms
                ref_pdb = pdb_id
        ref_coords = []
        for atm in ref_atoms:
            ref_coords.append(atm.coord)
        ref_coords = np.array(ref_coords)
        for pdb_id,emap in self.emaps.items():
            if not pdb_id == ref_pdb:
                cur_coords = []
                cur_atoms = list(emap.structure[0].get_atoms())
                for atm in cur_atoms:
                    cur_coords.append(atm.coord)
                cur_coords = np.array(cur_coords)
                sup = SVDSuperimposer()
                sup.set(ref_coords, cur_coords)
                sup.run()
                rotated_coords = sup.get_transformed()
                for i,atm in enumerate(emap.structure[0].get_atoms()):
                    atm.aligned_coord = rotated_coords[i]

        
    def _align_sequences(self,chains):
        records = []
        valid_ids = []
        for pdb_id,chain_list in chains.items():
            for chain in chain_list:
                valid_ids.append(pdb_id+":"+chain)
        for pdb_id,emap in self.emaps.items():
            seqIO = SeqIO.parse(emap.file_path, 'pdb-atom')
            for record in seqIO:
                if ":" not in record.id: 
                    record.id = pdb_id + ":" + record.id
                if record.id in valid_ids:
                    seqrec = SeqRecord(record.seq)
                    seqrec.id = record.id
                    seqrec.description = record.id
                    self.sequences[record.id] = record.seq
                    records.append(seqrec)
        SeqIO.write(records, self.temp_dir+"/data.fasta", "fasta")
        inp = self.temp_dir+"/data.fasta"
        out =  self.temp_dir+"/data_aligned.fasta"
        log = self.temp_dir + "/log.txt"
        muscle_cline = MuscleCommandline(input=inp,
                                 out=out,
                                 log=log)
        muscle_cline()
        seqIO = SeqIO.parse(out,"fasta")
        for record in seqIO:
            self.aligned_sequences[record.id] = record.seq
        # now lets save the updated sequence numbers
        for pdb_id,emap in self.emaps.items():
            model = emap.structure[0]
            for chain in model:
                if pdb_id+":"+chain.id in self.aligned_sequences:
                    seq_map={}
                    aligned_seq = self.aligned_sequences[pdb_id+":"+chain.id]
                    original_seq = self.sequences[pdb_id+":"+chain.id]
                    original_idx = 0
                    aligned_idx = 0
                    num_gaps = 0
                    for res in aligned_seq:
                        if not res=="-":
                            residue_obj = list(chain.get_residues())[original_idx]
                            seq_map[residue_obj.id[1]] = aligned_idx
                            original_idx+=1
                        else:
                            num_gaps+=1
                        aligned_idx+=1
                    for res in chain:
                        if res.id[1] in seq_map:
                            res.aligned_residue_number = seq_map[res.id[1]]
                    for resname,res in emap.eta_moieties.items():
                        if res.get_full_id()[2] == chain.id:
                            res.aligned_residue_number = res.id[1] + num_gaps

        


    # chains and eta_moieties should be dictionaries
    def process_emaps(self, chains=None, eta_moieties=None, include_residues=["TYR", "TRP"], **kwargs):
        ''' Processes :class:`~pyemap.emap` objects in order to generate protein graphs. 
        
        For a list of accepted kwargs, see the documentation for :func:`~pyemap.process_data.process`.

        Parameters
        -----------
        chains: dict of str: list of str, optional
            Chains to include for each PDB
        eta_moieties: dict of str: list of str, optional
            Dict containing list of ETA moieties(specified by their residue label) to include for each PDB
        
        Examples
        --------
        >>> my_pg = pyemap.common_paths.PDBGroup()
        >>> # Add pdbs 1u3d,1u3c,6PU0,4I6G,2J4D ...
        >>> eta_moieties = {'1u3d': ['FAD510(A)-2'], '1u3c': ['FAD510(A)-2'], '6PU0': ['FAD501(A)-2'], '4I6G': ['FAD900(A)-2'], '2J4D': ['FAD1498(A)-2']}
        >>> chains = {'1u3d': ['A'], '1u3c': ['A'], '6PU0': ['A'], '4I6G': ['A'], '2J4D': ['A']}
        >>> my_pg.process_emaps(chains=chains,eta_moieties=eta_moieties)

        '''
        self._reset_process()
        if chains==None:
            chains = {}
            for pdb_id in self.emaps:
                chains[pdb_id] = [self.emaps[pdb_id].chains[0]]
        self._align_sequences(chains)
        for pdb_id in self.emaps:
            if not eta_moieties==None:
                cur_eta_moieties = eta_moieties[pdb_id]
            else:
                cur_eta_moieties = None
            process(self.emaps[pdb_id], chains=chains[pdb_id], eta_moieties=cur_eta_moieties, include_residues=include_residues, **kwargs)
        self.parameters = kwargs
        self.included_chains = chains
        self.included_eta_moieties = eta_moieties
        self.included_standard_residues = include_residues

    def report_header(self):
        full_str=""
        full_str+= "Generated:\n" + str(datetime.datetime.now()) + "\n"
        full_str+="Parameters:\n"
        if not self.parameters:
            full_str+="Custom.\n"
        else:
            full_str+=str(self.parameters)
            full_str+="\n"
        full_str+="Chains:\n"
        if not self.included_chains:
            full_str+="Custom.\n"
        else:
            full_str+=str(self.included_chains)
            full_str+="\n"
        full_str+="Included non protein moieties:\n"
        if not self.included_eta_moieties:
            full_str+="Custom.\n"
        else:
            full_str+=str(self.included_eta_moieties)
            full_str+="\n"
        full_str+="Edge thresholds:\n"+str(self.edge_thresholds)+"\n"
        full_str+="Node labels:\n"+str(self.res_to_num_label) + "\n"
        full_str+="Node categories:\n" + str(self.num_label_to_res) + "\n"
        return full_str
    
    def general_report(self,dest=None):
        ''' Generates general report of all frequent subgraphs found in the analysis.

        Returns
        -------
        report: str
            General report of all frequent subgraphs found in the analysis.
        '''
        full_str="Overview of all subgraphs:\n"
        full_str+=self.report_header()
        full_str+="\nSubgraphs found:\n\n"
        for fsg in self.frequent_subgraphs:
            full_str+=self.frequent_subgraphs[fsg].general_report()+"\n"
        if dest:
            fi = open(dest, "w")
            fi.write(full_str)
            fi.close()
        return full_str

    def subgraph_report(self,sg_id,dest=None):
        ''' Generates detailed report for a given frequent subgraph.

        Parameters
        -----------
        sg_id: str
            ID corresponding to a :class:`~pyemap.common_paths.FrequentSubgraph` object 
        dest: str, optional
            Destination to write report to file

        Returns
        -------
        report: str
            Detailed report for a particular frequent subgraph.
        '''
        sg = self.frequent_subgraphs[sg_id]
        full_str="Full report for subgraph:" + str(sg_id) + "\n"
        full_str+=self.report_header() + "\n"
        full_str+= sg.full_report(self.emaps)
        if dest:
            fi = open(dest, "w")
            fi.write(full_str)
            fi.close()
        return full_str

    def _set_edge_labels(self, edge_thresholds):
        if edge_thresholds == None:
            edge_thresholds = [8.0, 12.0]
        self.edge_thresholds = edge_thresholds

    def _set_node_labels(self, node_labels, categories):
        self.res_to_num_label={}
        self.num_label_to_res={}
        if categories is not None and ("X" in node_labels or "X" in categories.values()):
            raise KeyError("X is reserved for unknown residue type. Do not use X as a key.")
        if not node_labels:
            num_label = 2
            for res in self.included_standard_residues:
                self.res_to_num_label[res_name_to_char[res]] = num_label
                self.num_label_to_res[num_label] = res_name_to_char[res]
                num_label+=1
            self.num_label_to_res[num_label] = "X"
            self.res_to_num_label["X"] = num_label
        else:
            self.res_to_num_label = node_labels
            self.num_label_to_res = categories
            num_label = len(self.num_label_to_res) + 2
            self.num_label_to_res[num_label] = "X"
            self.res_to_num_label["X"] = num_label

    def _get_edge_label(self, G, edge):
        dist = G.edges[edge]['distance']
        label = 2
        for thresh in self.edge_thresholds:
            if dist < thresh:
                return label
            else:
                label += 1
        return label

    def _get_numerical_node_label(self, u, pdb_id):
        if strip_res_number(u) in char_to_res_name:
            res_name = strip_res_number(u)
            result = self.res_to_num_label[res_name]
        elif (pdb_id+"_"+str(u)) in self.res_to_num_label:
            res_label = pdb_id+"_"+str(u)
            result = self.res_to_num_label[res_label]
        else:
            result = self.res_to_num_label["X"]
        return result

    def add_emap(self, emap_obj):
        ''' Adds a parsed :class:`~pyemap.emap` object to the PDB group.

        Parameters
        ----------
            emap_obj: :class:`~pyemap.emap` object 
                Parsed PDB generated by :func:`~pyemap.parser.parse` or :func:`~pyemap.parser.fetch_and_parse`
        '''
        if emap_obj.pdb_id not in self.emaps:
            self.emaps[emap_obj.pdb_id] = emap_obj
            print("Added emap object with PDB ID: " + emap_obj.pdb_id)
        else:
            print("An emap object with PDB ID:" + str(emap_obj.pdb_id) + " is already in the data set. Skipping...")

    
    def generate_graph_database(self, node_labels=None, categories=None, edge_thresholds=None):
        ''' Generates graph database for analysis by GSpan using specified node labels, node categories, and edge thresholds.

        Parameters
        ----------
            node_labels: dict of str:int, optional
                Dict which maps residue labels to their numerical label for usage in the gSpan algorithm. Labels for non-standard
                residues should be preceded with the 4 character PDB ID followed by an underscore (e.g. 1u3d_FAD510(A)-2)
            categories: dict of int:str, optional
                Dict which maps numerical label to node category (which will appear in generic representation of frequent subgraph)
            edge_thresholds: list of float, optional
                List of edge thresholds which are used to categorize edges for usage in the gSpan algorithm
        
        Examples
        ---------
        >>> # labels for each type of residue included in analysis, including eta moieties grouped as a category
        >>> node_labels = {'1u3d_FAD510(A)-2': 2, '1u3c_FAD510(A)-2': 2, '6PU0_FAD501(A)-2': 2, 
                           '4I6G_FAD900(A)-2': 2, '2J4D_FAD1498(A)-2': 2, '1u3d_ANP511(A)': 3, 
                           'W': 4, 'Y': 5}
        >>> categories = {2: 'Fla', 3: 'Ade', 4: 'W', 5: 'Y'}
        >>> # edge length thresholds for categorizing edges
        >>> edge_thesholds = [8.0, 12.0]
        >>> my_pg.generate_graph_database(node_labels=node_labels,categories=categories,edge_thresholds=edge_thresholds)

        '''
        #TODO: check for if node labels make sense
        self._clean_subgraphs()
        self._set_node_labels(node_labels, categories)
        self._set_edge_labels(edge_thresholds)
        f = open(os.path.join(self.temp_dir, 'graphdatabase.txt'), "w")
        for i, key in enumerate(self.emaps):
            G = self.emaps[key].init_graph
            f.write("t # " + str(i) + "\n")
            for i, node in enumerate(G.nodes):
                f.write("v " + str(i) + " " + str(self._get_numerical_node_label(node,key)) + "\n")
            for i, edge in enumerate(G.edges):
                f.write("e " + str(list(G.nodes()).index(edge[0])) + " " + str(list(G.nodes()).index(edge[1])) + " " +
                        str(self._get_edge_label(G, edge)) + "\n")
        f.write("t # -1")

    def run_gspan(self, support, lower_bound=4):
        ''' Runs gSpan algorithm to mine for frequent subgraphs, and then identifies each occurence of each frequent subgraph in each PDB which supports it.
        
        Parameters
        ----------
            support: int, optional
                Minimum support number of subgraphs in the search space 
            lower_bound: int, optional
                Minimum number of nodes for subgraphs in the search space
        '''
        import sys
        old_stdout = sys.stdout
        f = open(os.path.join(self.temp_dir, 'gspan_results.out'), "w")
        sys.stdout = f
        from gspan_mining.config import parser
        from gspan_mining.main import main
        args_str = '-s ' + str(support) + ' -d False -l ' + str(lower_bound) + ' -p False -w True ' + str(
            os.path.join(self.temp_dir, 'graphdatabase.txt'))
        FLAGS, _ = parser.parse_known_args(args=args_str.split())
        gs = main(FLAGS)
        # give us our old standard output back
        sys.stdout = old_stdout
        f.close()
        self._generate_frequent_subgraphs()


    def _generate_frequent_subgraphs(self):
        buff = open(os.path.join(self.temp_dir, 'gspan_results.out'), "r")
        subgraphs = []
        lines = buff.readlines()
        line_idx = 0
        while line_idx < len(lines):
            line = lines[line_idx]
            if len(line.split()) == 3 and line.split()[0] == "t" and line.split()[1] == "#":
                graph_number = line.split()[2]
                line_idx += 1
                start_idx = line_idx - 1
                G = nx.Graph()
                line = lines[line_idx]
                while "---" not in line:
                    line = lines[line_idx]
                    if len(line.split()) > 1 and line.split()[0] == "v":
                        node_idx = int(line.split()[1])
                        node_label = int(line.split()[2])
                        G.add_node(node_idx)
                        G.nodes[node_idx]['label'] = self.num_label_to_res[node_label]
                        G.nodes[node_idx]['num_label'] = node_label
                    if len(line.split()) > 1 and line.split()[0] == "e":
                        idx1 = int(line.split()[1])
                        idx2 = int(line.split()[2])
                        edge_label = int(line.split()[3])
                        G.add_edge(idx1, idx2, label=edge_label)
                        G.edges[(idx1, idx2)]['num_label'] = edge_label
                    if "where" in line:
                        pdb_list_by_index = line[7:-2].strip('][').split(', ')
                        pdb_list_by_index = list(np.array(pdb_list_by_index, dtype=int))
                        pdb_list = list(self.emaps.keys())
                        support = []
                        for idx in pdb_list_by_index:
                            support.append(pdb_list[idx])
                        subgraphs.append(FrequentSubgraph(G, graph_number, support))
                    line_idx += 1
            line_idx += 1
        buff.close()
        subgraphs.sort(key=lambda x: x.support_number, reverse=True)
        for sg in subgraphs:
            for pdb_id in sg.support:
                sg.specific_subgraphs[pdb_id] = self._find_subgraph_in_pdb(sg, pdb_id)
            self.frequent_subgraphs[sg.id] = sg

    def _generate_specific_subgraph(self, mapping, protein_graph, generic_subgraph):
        mapping = dict((v, k) for k, v in mapping.items())
        specific_subgraph = generic_subgraph.copy()
        specific_subgraph = nx.relabel_nodes(specific_subgraph, mapping)
        nodes = []
        for node in specific_subgraph.nodes():
            specific_subgraph.nodes[node]['shape'] = protein_graph.nodes[node]['shape']
            specific_subgraph.nodes[node]['label'] = str(node)
            specific_subgraph.nodes[node]['resnum'] = protein_graph.nodes[node]['resnum']
            specific_subgraph.nodes[node]['aligned_resnum'] = protein_graph.nodes[node]['aligned_resnum']
            nodes.append((node,specific_subgraph.nodes[node]['resnum']))
        for edge in specific_subgraph.edges():
            for key in protein_graph.edges[edge]:
                specific_subgraph.edges[edge][key] = protein_graph.edges[edge][key]
        # now the sorted version
        nodes.sort(key=lambda x: x[1])
        nodes_only = []
        for node,resnum in nodes:
            nodes_only.append(node)
        sorted_G = nx.Graph()
        sorted_G.add_nodes_from(nodes_only)
        sorted_G.add_edges_from(specific_subgraph.edges(data=True))
        for node in sorted_G.nodes:
            sorted_G.nodes[node]['shape'] = protein_graph.nodes[node]['shape']
            sorted_G.nodes[node]['label'] = str(node)
            sorted_G.nodes[node]['resnum'] = protein_graph.nodes[node]['resnum']
            sorted_G.graph['pdb_id'] = protein_graph.graph['pdb_id']
            sorted_G.nodes[node]['aligned_resnum'] = protein_graph.nodes[node]['aligned_resnum']
        return sorted_G
        #return specific_subgraph

    def _find_subgraph_in_pdb(self, subgraph, pdb_id):
        generic_subgraph = subgraph.generic_subgraph
        if pdb_id not in subgraph.support:
            return []
        protein_graph = self.emaps[pdb_id].init_graph
        for node in protein_graph.nodes:
            protein_graph.nodes[node]['num_label'] = self._get_numerical_node_label(node,pdb_id)
        for edge in protein_graph.edges:
            protein_graph.edges[edge]['num_label'] = self._get_edge_label(protein_graph, edge)
        GM = isomorphism.GraphMatcher(protein_graph, generic_subgraph, node_match=node_match, edge_match=edge_match)
        subgraph_isos = GM.subgraph_monomorphisms_iter()
        sgs = []
        for mapping in subgraph_isos:
            sg = self._generate_specific_subgraph(mapping, protein_graph, generic_subgraph)
            sgs.append(sg)
        return sgs
